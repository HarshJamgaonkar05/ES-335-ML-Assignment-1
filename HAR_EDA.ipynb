{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a8eb10",
   "metadata": {},
   "source": [
    "# Running the CombinScrit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a641e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:25: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_x = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_x_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:26: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_y = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_y_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:27: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_z = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_z_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:31: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  subject_train = pd.read_csv(os.path.join(train_path,\"subject_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:34: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y = pd.read_csv(os.path.join(train_path,\"y_train.txt\"),delim_whitespace=True,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:80: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_x = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_x_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:81: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_y = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_y_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:82: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_z = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_z_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:85: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  subject_test = pd.read_csv(os.path.join(test_path,\"subject_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_3052\\1866655394.py:88: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y = pd.read_csv(os.path.join(test_path,\"y_test.txt\"),delim_whitespace=True,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the testing data\n",
      "Done Combining the data\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Give the path of the test and train folder of UCI HAR Dataset\n",
    "train_path = \"./UCI HAR Dataset/train\"\n",
    "test_path = \"./UCI HAR Dataset/test\"\n",
    "\n",
    "# Dictionary of activities. Provided by the dataset.\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING'            ,\n",
    "    2: 'WALKING_UPSTAIRS'   ,\n",
    "    3: 'WALKING_DOWNSTAIRS' ,\n",
    "    4: 'SITTING'            ,\n",
    "    5: 'STANDING'           ,\n",
    "    6: 'LAYING'             ,\n",
    "}\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Traing Data\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_x_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_y_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_z_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_train = pd.read_csv(os.path.join(train_path,\"subject_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(train_path,\"y_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_train.values):\n",
    "\n",
    "    sub_idxs = np.where( subject_train.iloc[:,0] == subject )[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        # make the folder directory if it does not exist\n",
    "        if not os.path.exists(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "        save_path = os.path.join(\"Combined\",\"Train\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the training data\")\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Test Data               \n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_x_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_y_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_z_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_test = pd.read_csv(os.path.join(test_path,\"subject_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(test_path,\"y_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_test.values):\n",
    "    \n",
    "        sub_idxs = np.where( subject_test.iloc[:,0] == subject )[0]\n",
    "        labels = y.loc[sub_idxs]\n",
    "\n",
    "        # Toggle through all the labels.\n",
    "        for label in np.unique(labels.values):\n",
    "    \n",
    "            if not os.path.exists(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label])):\n",
    "                os.makedirs(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label]))\n",
    "    \n",
    "            label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "    \n",
    "            accx = []\n",
    "            accy = []\n",
    "            accz = []\n",
    "            for idx in label_idxs:\n",
    "                if accx is not None:\n",
    "                    accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                    accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                    accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "    \n",
    "                else:\n",
    "                    accx = total_acc_x.loc[idx]\n",
    "                    accy = total_acc_y.loc[idx]\n",
    "                    accz = total_acc_z.loc[idx]\n",
    "    \n",
    "            # saving the data into csv file\n",
    "            data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "            save_path = os.path.join(\"Combined\",\"Test\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "            data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the testing data\")\n",
    "print(\"Done Combining the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc15ff",
   "metadata": {},
   "source": [
    "# Running the MakeDataset.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332a2246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Train Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Test Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Final Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# USE THE BELOW GIVEN DATA FOR TRAINING and TESTING purposes\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d81c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.19648   -0.1606898 -0.740178 ]\n",
      " [ 1.22203   -0.2672951 -0.7717485]\n",
      " [ 1.22311   -0.4338634 -0.7678422]\n",
      " ...\n",
      " [ 0.4974957 -0.2795907 -0.2029592]\n",
      " [ 0.5064167 -0.286091  -0.2564634]\n",
      " [ 0.5609918 -0.302237  -0.2553743]]\n",
      "---------------\n",
      "[[ 1.293474   -0.3140436  -0.2480047 ]\n",
      " [ 1.258798   -0.2909032  -0.5137133 ]\n",
      " [ 1.258902   -0.3451832  -0.505633  ]\n",
      " ...\n",
      " [ 0.6532789  -0.02082443 -0.06393618]\n",
      " [ 0.7110597  -0.1404382  -0.00802015]\n",
      " [ 0.8174469  -0.2235447  -0.02307176]]\n",
      "---------------\n",
      "[2 6 5 2 2 2 1 1 5 4 1 4 1 1 6 2 3 1 1 4 3 3 5 6 5 1 3 6 4 5 5 2 5 1 1 6 4\n",
      " 3 3 3 3 4 6 3 4 1 2 2 6 5 5 3 6 6 4 3 4 2 4 5 5 5 5 4 6 6 4 5 3 4 3 1 4 4\n",
      " 3 1 5 2 3 6 1 4 2 2 5 2 1 3 6 6 2 5 6 1 3 5 2 3 4 4 2 5 1 1 1 3 4 5 6 1 3\n",
      " 6 5 4 2 2 6 2 6 6 3 1 4 6 2 2]\n",
      "---------------\n",
      "[3 1 2 5 5 1 1 5 3 2 6 5 6 5 6 1 6 5 2 5 4 3 2 2 1 4 6 4 1 2 6 2 4 4 3 6 6\n",
      " 3 1 5 3 2 1 4 4 4 5 1 3 3 3 6 2 4]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(\"---------------\")\n",
    "print(X_test[0])\n",
    "print(\"---------------\")\n",
    "print(y_train)\n",
    "print(\"---------------\")\n",
    "print(y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44225d4c",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "Plot the waveform for one sample data from each activity class. Are you able to see any difference/similarities between the activities? You can plot a subplot having 6 columns to show differences/similarities between the activities. Do you think the model will be able to classify the activities based on the data? **[0.5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40844aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
