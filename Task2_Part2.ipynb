{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284e2aa4",
   "metadata": {},
   "source": [
    "## Decision Tree for Human Activity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ce3c4",
   "metadata": {},
   "source": [
    "### Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd54a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0f4cb",
   "metadata": {},
   "source": [
    "### Running CombineScript.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a560c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:35: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_x = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_x_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:36: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_y = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_y_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:37: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_z = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_z_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:41: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  subject_train = pd.read_csv(os.path.join(train_path,\"subject_train.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:44: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y = pd.read_csv(os.path.join(train_path,\"y_train.txt\"),delim_whitespace=True,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:90: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_x = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_x_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:91: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_y = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_y_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:92: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  total_acc_z = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_z_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:95: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  subject_test = pd.read_csv(os.path.join(test_path,\"subject_test.txt\"),delim_whitespace=True,header=None)\n",
      "C:\\Users\\Parth Dembla\\AppData\\Local\\Temp\\ipykernel_28412\\86021575.py:98: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  y = pd.read_csv(os.path.join(test_path,\"y_test.txt\"),delim_whitespace=True,header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the testing data\n",
      "Done Combining the data\n"
     ]
    }
   ],
   "source": [
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#\n",
    "#                                   ES335- Machine Learning- Assignment 1\n",
    "#\n",
    "# This script combines the data from the UCI HAR Dataset into a more usable format.\n",
    "# The data is combined into a single csv file for each subject and activity. \n",
    "# The data is then stored in the Combined folder.\n",
    "#\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Give the path of the test and train folder of UCI HAR Dataset\n",
    "train_path = \"./UCI HAR Dataset/train\"\n",
    "test_path = \"./UCI HAR Dataset/test\"\n",
    "\n",
    "# Dictionary of activities. Provided by the dataset.\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING'            ,\n",
    "    2: 'WALKING_UPSTAIRS'   ,\n",
    "    3: 'WALKING_DOWNSTAIRS' ,\n",
    "    4: 'SITTING'            ,\n",
    "    5: 'STANDING'           ,\n",
    "    6: 'LAYING'             ,\n",
    "}\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Traing Data\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_x_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_y_train.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(train_path,\"Inertial Signals\",\"total_acc_z_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_train = pd.read_csv(os.path.join(train_path,\"subject_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(train_path,\"y_train.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_train.values):\n",
    "\n",
    "    sub_idxs = np.where( subject_train.iloc[:,0] == subject )[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        # make the folder directory if it does not exist\n",
    "        if not os.path.exists(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\",\"Train\",ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "        save_path = os.path.join(\"Combined\",\"Train\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the training data\")\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                        # Combining Test Data               \n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_x_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_y_test.txt\"),delim_whitespace=True,header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(test_path,\"Inertial Signals\",\"total_acc_z_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_test = pd.read_csv(os.path.join(test_path,\"subject_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(test_path,\"y_test.txt\"),delim_whitespace=True,header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_test.values):\n",
    "    \n",
    "        sub_idxs = np.where( subject_test.iloc[:,0] == subject )[0]\n",
    "        labels = y.loc[sub_idxs]\n",
    "\n",
    "        # Toggle through all the labels.\n",
    "        for label in np.unique(labels.values):\n",
    "    \n",
    "            if not os.path.exists(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label])):\n",
    "                os.makedirs(os.path.join(\"Combined\",\"Test\",ACTIVITIES[label]))\n",
    "    \n",
    "            label_idxs = labels[labels.iloc[:,0] == label].index\n",
    "    \n",
    "            accx = []\n",
    "            accy = []\n",
    "            accz = []\n",
    "            for idx in label_idxs:\n",
    "                if accx is not None:\n",
    "                    accx = np.hstack((accx,total_acc_x.loc[idx][64:]))\n",
    "                    accy = np.hstack((accy,total_acc_y.loc[idx][64:]))\n",
    "                    accz = np.hstack((accz,total_acc_z.loc[idx][64:]))\n",
    "    \n",
    "                else:\n",
    "                    accx = total_acc_x.loc[idx]\n",
    "                    accy = total_acc_y.loc[idx]\n",
    "                    accz = total_acc_z.loc[idx]\n",
    "    \n",
    "            # saving the data into csv file\n",
    "            data = pd.DataFrame({'accx':accx,'accy':accy,'accz':accz})\n",
    "            save_path = os.path.join(\"Combined\",\"Test\",ACTIVITIES[label],f\"Subject_{subject}.csv\")\n",
    "            data.to_csv(save_path,index=False)\n",
    "\n",
    "print(\"Done Combining the testing data\")\n",
    "print(\"Done Combining the data\")\n",
    "\n",
    "#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894eecbb",
   "metadata": {},
   "source": [
    "### Running the MakeDataset.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2f614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "#\n",
    "#                                   ES335- Machine Learning- Assignment 1\n",
    "#\n",
    "# This file is used to create the dataset for the mini-project. The dataset is created by reading the data from\n",
    "# the Combined folder. The data is then split into training, testing, and validation sets. This split is supposed\n",
    "# to be used for all the modeling purposes.\n",
    "#\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Library imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\",\"SITTING\",\"STANDING\",\"WALKING\",\"WALKING_DOWNSTAIRS\",\"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\":1,\"WALKING_UPSTAIRS\":2,\"WALKING_DOWNSTAIRS\":3,\"SITTING\":4,\"STANDING\":5,\"LAYING\":6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Train Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Test Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "dataset_dir = os.path.join(combined_dir,\"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir,folder))\n",
    "    for file in files:\n",
    "\n",
    "        df = pd.read_csv(os.path.join(dataset_dir,folder,file),sep=\",\",header=0)\n",
    "        df = df[offset:offset+time*50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "                                                # Final Dataset\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# USE THE BELOW GIVEN DATA FOR TRAINING and TESTING purposes\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train,X_test))\n",
    "y = np.concatenate((y_train,y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=seed,stratify=y)\n",
    "\n",
    "print(\"Training data shape: \",X_train.shape)\n",
    "print(\"Testing data shape: \",X_test.shape)\n",
    "\n",
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
